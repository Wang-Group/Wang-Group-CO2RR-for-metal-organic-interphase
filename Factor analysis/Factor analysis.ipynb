{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T11:32:53.226439Z",
     "start_time": "2024-06-24T11:31:30.994217Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 读取A和B两个CSV文件\n",
    "A = pd.read_csv('MFFmatrix-onlyS.csv')\n",
    "B = pd.read_csv('Rdkitmatrix+sym descriptor-only S.csv')\n",
    "\n",
    "# 计算A数据的相关性系数矩阵\n",
    "A_correlation_matrix = A.corr()\n",
    "\n",
    "# 打印A的相关性系数矩阵\n",
    "print(\"Correlation Matrix of A:\\n\", A_correlation_matrix)\n",
    "\n",
    "# 找到相关性系数为1的列名（排除自相关）\n",
    "to_remove = set()\n",
    "for col in A_correlation_matrix.columns:\n",
    "    for idx in A_correlation_matrix.index:\n",
    "        if col != idx and A_correlation_matrix.loc[idx, col] == 1:\n",
    "            if col != idx:  # 如果变量名字不同\n",
    "                to_remove.add(col)\n",
    "                break  # 找到一个就跳出循环\n",
    "\n",
    "# 打印要删除的变量名字\n",
    "print(\"Variables to remove:\\n\", to_remove)\n",
    "\n",
    "# 删除相关性系数为1的列\n",
    "A1 = A.drop(columns=to_remove)\n",
    "\n",
    "# 打印更新后的A数据\n",
    "print(\"Updated A Data:\\n\", A1)\n",
    "\n",
    "# 保存新的A1 CSV文件\n",
    "A1.to_csv('A1.csv', index=False)\n",
    "print(\"Updated A1 CSV saved to 'A1.csv'\")\n",
    "\n",
    "# 读取A1 CSV文件\n",
    "A1 = pd.read_csv('A1.csv')\n",
    "\n",
    "# 初始化标准化器\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 标准化A1数据\n",
    "A1_scaled = scaler.fit_transform(A1)\n",
    "A1_scaled = pd.DataFrame(A1_scaled, columns=A1.columns)\n",
    "A1_scaled.drop(columns=A1_scaled.std()[A1_scaled.std() == 0].index, inplace=True)\n",
    "\n",
    "# 标准化B数据\n",
    "B_scaled = scaler.fit_transform(B)\n",
    "B_scaled = pd.DataFrame(B_scaled, columns=B.columns)\n",
    "B_scaled.drop(columns=B_scaled.std()[B_scaled.std() == 0].index, inplace=True)\n",
    "\n",
    "# 确保数据中没有缺失值\n",
    "A1.dropna(inplace=True)\n",
    "B_scaled.dropna(inplace=True)\n",
    "\n",
    "# 初始化一个空的DataFrame来存储相关性系数\n",
    "correlation_matrix = pd.DataFrame(index=A1.columns, columns=B_scaled.columns)\n",
    "\n",
    "# 计算相关性系数\n",
    "for a_col in A1.columns:\n",
    "    for b_col in B_scaled.columns:\n",
    "        correlation = A1[a_col].corr(B_scaled[b_col])\n",
    "        correlation_matrix.at[a_col, b_col] = correlation\n",
    "\n",
    "# 将相关性矩阵转换为浮点数类型\n",
    "correlation_matrix = correlation_matrix.astype(float)\n",
    "# 获取矩阵的第一列的行名和第一行的列名\n",
    "first_column_row_names = correlation_matrix.index\n",
    "first_row_column_names = correlation_matrix.columns\n",
    "\n",
    "# 找到重复的列名\n",
    "columns_to_drop = [col_name for col_name in first_row_column_names if col_name in first_column_row_names]\n",
    "\n",
    "# 删除重复列名所在的列\n",
    "correlation_matrix = correlation_matrix.drop(columns=columns_to_drop)\n",
    "\n",
    "# 删除某一行或某一列全是NaN的行和列\n",
    "correlation_matrix.dropna(axis=0, how='all', inplace=True)\n",
    "correlation_matrix.dropna(axis=1, how='all', inplace=True)\n",
    "# 打印更新后的相关性矩阵\n",
    "print(\"Updated Correlation Matrix:\\n\", correlation_matrix)\n",
    "# 绘制热图\n",
    "plt.figure(figsize=(150, 150))  # 调整图像大小以适应较小的矩阵\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False,center=0, annot_kws={\"size\": 30}, cbar=True)\n",
    "plt.title('Updated Correlation Matrix Heatmap between MFF and Physicochemical properties features', fontsize=40)\n",
    "plt.xlabel('Physicochemical properties', fontsize=80)\n",
    "plt.ylabel('MFF', fontsize=80)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=80) # 设置x轴字体大小\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=80) # 设置y轴字体大小\n",
    "plt.show()\n",
    "print(correlation_matrix.shape)\n",
    "# 将更新后的相关性矩阵保存为CSV文件\n",
    "correlation_matrix.to_csv('updated_correlation_matrix_between_Original_and_Encoded_Features.csv')\n",
    "print(\"Updated correlation matrix saved to 'updated_correlation_matrix_between_Original_and_Encoded_Features.csv'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-24T11:53:37.365740Z",
     "start_time": "2024-06-24T11:53:18.897489Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# 读取CSV文件\n",
    "file_path = 'updated_correlation_matrix_between_Original_and_Encoded_Features.csv'\n",
    "data = pd.read_csv(file_path, index_col=0)\n",
    "plt.figure(figsize=(200, 200))  # 调整图像大小以适应较小的矩阵\n",
    "ax=sns.heatmap(data, cmap='coolwarm', annot=False,center=0, annot_kws={\"size\": 100}, cbar=True)\n",
    "plt.title('Updated Correlation Matrix Heatmap between MFF and Physicochemical properties features', fontsize=40)\n",
    "plt.xlabel('Physicochemical properties', fontsize=40)\n",
    "plt.ylabel('MFF', fontsize=40)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), fontsize=40) # 设置x轴字体大小\n",
    "ax.set_yticklabels(ax.get_yticklabels(), fontsize=40) # 设置y轴字体大小\n",
    "# 设置颜色条字体大小\n",
    "cbar = ax.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=60)  # 调整颜色条刻度字体大小\n",
    "#cbar.set_label('Correlation Value', fontsize=60)  # 设置颜色条标签及其字体大小\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T02:32:15.706162Z",
     "start_time": "2024-06-11T02:32:15.679526Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Alignment\n",
    "\n",
    "# 读取相关性矩阵CSV文件\n",
    "correlation_matrix_path = 'updated_correlation_matrix_between_Original_and_Encoded_Features.csv'\n",
    "updated_correlation_matrix = pd.read_csv(correlation_matrix_path, index_col=0)\n",
    "\n",
    "def correlate_features(feature_to_search):\n",
    "    threshold_similar = 0.7\n",
    "    threshold_explain = 0.4\n",
    "\n",
    "    similar_features = []\n",
    "    explain_features = []\n",
    "\n",
    "    if feature_to_search in reordered_RDkit.columns:\n",
    "        Similar = reordered_RDkit_corr.loc[feature_to_search, :]\n",
    "        for rdkit in reordered_RDkit.columns:\n",
    "            if rdkit != feature_to_search and abs(Similar[rdkit]) > threshold_similar:\n",
    "                similar_features.append((rdkit, Similar[rdkit]))\n",
    "        similar_features = sorted(similar_features, key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        # 如果没有找到相似特征，填入 'None'\n",
    "        if not similar_features:\n",
    "            similar_features.append(('None', 'None'))\n",
    "\n",
    "        if feature_to_search in updated_correlation_matrix.index:\n",
    "            representation = updated_correlation_matrix.loc[feature_to_search, :]\n",
    "            for mff in updated_correlation_matrix.columns:\n",
    "                if pd.notna(representation[mff]) and abs(representation[mff]) > threshold_explain:\n",
    "                    explain_features.append((mff, representation[mff]))\n",
    "\n",
    "        if feature_to_search in updated_correlation_matrix.columns:\n",
    "            representation = updated_correlation_matrix.loc[:, feature_to_search]\n",
    "            for mff in updated_correlation_matrix.index:\n",
    "                if pd.notna(representation[mff]) and abs(representation[mff]) > threshold_explain:\n",
    "                    explain_features.append((mff, representation[mff]))\n",
    "\n",
    "        explain_features = list(set(explain_features))\n",
    "        explain_features = sorted(explain_features, key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        # 如果没有找到解释特征，填入 'None'\n",
    "        if not explain_features:\n",
    "            explain_features.append(('None', 'None'))\n",
    "\n",
    "    elif feature_to_search in updated_correlation_matrix.index:\n",
    "        explain_features = ['MFF descriptor itself']\n",
    "\n",
    "    return similar_features, explain_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T02:36:28.327822Z",
     "start_time": "2024-06-11T02:36:28.218680Z"
    },
    "run_control": {
     "marked": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 读取 feature_to_search 列表的 CSV 文件路径\n",
    "features_to_search_path = 'S体系/20240611/S-体系-all metrics/shap_results-n-PrOH/MLP-top-features.csv'\n",
    "features_to_search_df = pd.read_csv(features_to_search_path, encoding='utf-8')\n",
    "# 读取 product 信息的 CSV 文件路径\n",
    "product_info_path = 'S体系/20240611/S-体系-all metrics/shap_results-n-PrOH/MLP-features-effects.csv'\n",
    "product_info_df = pd.read_csv(product_info_path, encoding='utf-8')\n",
    "\n",
    "# 调试信息：检查列名\n",
    "print(\"Features to search columns:\", features_to_search_df.columns)\n",
    "print(\"Product info columns:\", product_info_df.columns)\n",
    "\n",
    "# 预处理，确保特殊字符不会影响后续操作\n",
    "features_to_search_df.columns = features_to_search_df.columns.str.replace('/', '_').str.replace(' ', '_')\n",
    "product_info_df.columns = product_info_df.columns.str.replace('/', '_').str.replace(' ', '_')\n",
    "\n",
    "# 调试信息：检查替换后的列名\n",
    "print(\"Processed features to search columns:\", features_to_search_df.columns)\n",
    "print(\"Processed product info columns:\", product_info_df.columns)\n",
    "\n",
    "# 创建一个空的列表来存储所有的结果\n",
    "results_list = []\n",
    "\n",
    "# 处理每个 feature_to_search 并填入结果列表\n",
    "for index, row in features_to_search_df.iterrows():\n",
    "    feature_to_search = row[0]\n",
    "    similar_features, explain_features = correlate_features(feature_to_search)\n",
    "\n",
    "    product_info = product_info_df.loc[product_info_df['Feature'] == feature_to_search, 'Effect'].values\n",
    "    product_value = product_info[0] if len(product_info) > 0 else ''\n",
    "\n",
    "    # 确保所有条目都是包含两个值的元组\n",
    "    similar_features = [item if isinstance(item, tuple) else ('None', 'None') for item in similar_features]\n",
    "    \n",
    "    max_len = max(len(similar_features), len(explain_features), 1)\n",
    "#这里要改名字\n",
    "    temp_df = pd.DataFrame({\n",
    "        'Descriptor of interest': [feature_to_search] * max_len,\n",
    "        'Effect on n-PrOH': [product_value] * max_len,\n",
    "        'Similar Features': [f\"{feature}, {correlation}\" for feature, correlation in similar_features] + [''] * (max_len - len(similar_features)),\n",
    "        'MFF': [f\"{item[0]}, {item[1]}\" if isinstance(item, tuple) else item for item in explain_features] + [''] * (max_len - len(explain_features))\n",
    "    })\n",
    "\n",
    "    results_list.append(temp_df)\n",
    "\n",
    "results_df = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "csv_save_dir = '20240611-S体系-data explanation'\n",
    "os.makedirs(csv_save_dir, exist_ok=True)\n",
    "\n",
    "csv_file_path = os.path.join(csv_save_dir, 'n-PrOH-features_analysis_results.csv')\n",
    "results_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "excel_file_path = os.path.join(csv_save_dir, 'n-PrOH-features_analysis_results.xlsx')\n",
    "results_df.to_excel(excel_file_path, index=False, sheet_name='Analysis Results')\n",
    "\n",
    "wb = load_workbook(excel_file_path)\n",
    "ws = wb['Analysis Results']\n",
    "\n",
    "current_feature = None\n",
    "start_row = 2\n",
    "\n",
    "for row in range(2, ws.max_row + 1):\n",
    "    feature = ws[f'A{row}'].value\n",
    "    if feature == current_feature:\n",
    "        continue\n",
    "    else:\n",
    "        if current_feature is not None:\n",
    "            ws.merge_cells(start_row=start_row, start_column=1, end_row=row-1, end_column=1)\n",
    "            ws[f'A{start_row}'].alignment = Alignment(vertical='center')\n",
    "        current_feature = feature\n",
    "        start_row = row\n",
    "\n",
    "if current_feature is not None:\n",
    "    ws.merge_cells(start_row=start_row, start_column=1, end_row=ws.max_row, end_column=1)\n",
    "    ws[f'A{start_row}'].alignment = Alignment(vertical='center')\n",
    "\n",
    "current_feature = None\n",
    "current_effect = None\n",
    "start_row = 2\n",
    "\n",
    "for row in range(2, ws.max_row + 1):\n",
    "    effect = ws[f'B{row}'].value\n",
    "    if effect == current_effect:\n",
    "        continue\n",
    "    else:\n",
    "        if current_effect is not None:\n",
    "            ws.merge_cells(start_row=start_row, start_column=2, end_row=row-1, end_column=2)\n",
    "            ws[f'B{start_row}'].alignment = Alignment(vertical='center')\n",
    "        current_effect = effect\n",
    "        start_row = row\n",
    "\n",
    "if current_effect is not None:\n",
    "    ws.merge_cells(start_row=start_row, start_column=2, end_row=ws.max_row, end_column=2)\n",
    "    ws[f'B{start_row}'].alignment = Alignment(vertical='center')\n",
    "\n",
    "wb.save(excel_file_path)\n",
    "print(f\"Results saved to '{csv_file_path}' and '{excel_file_path}'\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-22T05:06:23.766937Z",
     "start_time": "2024-06-22T05:05:46.046624Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from factor_analyzer import FactorAnalyzer, calculate_kmo, calculate_bartlett_sphericity\n",
    "\n",
    "# 读取相关性系数矩阵的CSV文件\n",
    "file_path = 'updated_correlation_matrix_between_Original_and_Encoded_Features.csv'\n",
    "df = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "# 数据预处理，去掉包含NaN或无穷大值的行\n",
    "df = df.loc[~df.isin([np.nan, np.inf, -np.inf]).any(axis=1)]\n",
    "\n",
    "# 转置数据，使每一行作为变量\n",
    "df_transposed = df.transpose()\n",
    "\n",
    "# 检查数据的适合性\n",
    "kmo_all, kmo_model = calculate_kmo(df_transposed)\n",
    "bartlett_chi_square, bartlett_p_value = calculate_bartlett_sphericity(df_transposed)\n",
    "\n",
    "print(f\"KMO Test: {kmo_model}\")\n",
    "print(f\"Bartlett's Test: Chi-square={bartlett_chi_square}, p-value={bartlett_p_value}\")\n",
    "\n",
    "if bartlett_p_value < 0.05:\n",
    "    print(\"The data is suitable for factor analysis.\")\n",
    "    \n",
    "    # 因子分析\n",
    "    Load_Matrix = FactorAnalyzer(n_factors=len(df_transposed.T), rotation=None, method='principal')\n",
    "    Load_Matrix.fit(df_transposed)\n",
    "    \n",
    "    # 绘制碎石图以确定因子数量\n",
    "    ev, v = Load_Matrix.get_eigenvalues()\n",
    "    print('\\n相关矩阵特征值：', ev)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(range(1, df_transposed.shape[1] + 1), ev)\n",
    "    plt.plot(range(1, df_transposed.shape[1] + 1), ev)\n",
    "    plt.title('特征值和因子个数的变化', fontdict={'weight': 'normal', 'size': 25})\n",
    "    plt.xlabel('Factors', fontdict={'weight': 'normal', 'size': 15})\n",
    "    plt.ylabel('Eigenvalues', fontdict={'weight': 'normal', 'size': 15})\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "    # 进行旋转后的因子分析\n",
    "    Load_Matrix_rotated = FactorAnalyzer(rotation='varimax', n_factors=18, method='principal')\n",
    "    Load_Matrix_rotated.fit(df_transposed)\n",
    "    f_contribution_var_rotated = Load_Matrix_rotated.get_factor_variance()\n",
    "    matrices_var_rotated = pd.DataFrame()\n",
    "    matrices_var_rotated[\"特征值\"] = f_contribution_var_rotated[0]\n",
    "    matrices_var_rotated[\"方差贡献率\"] = f_contribution_var_rotated[1]\n",
    "    matrices_var_rotated[\"方差累计贡献率\"] = f_contribution_var_rotated[2]\n",
    "    print(\"旋转后的载荷矩阵的贡献率\")\n",
    "    print(matrices_var_rotated)\n",
    "    print(\"旋转后的成分矩阵\")\n",
    "    print(Load_Matrix_rotated.loadings_)\n",
    "    \n",
    "    # 可视化因子载荷矩阵\n",
    "    Load_Matrix = Load_Matrix_rotated.loadings_\n",
    "    df_loadings = pd.DataFrame(np.abs(Load_Matrix), index=df_transposed.columns, columns=[f'Factor{i+1}' for i in range(18)])\n",
    "    \n",
    "    plt.rcParams['font.family'] = 'Times New Roman' # 设置英文字体为Times New Roman \n",
    "    plt.figure(figsize=(100, 100))\n",
    "    ax = sns.heatmap(df_loadings, center=0, annot=True, cmap=\"coolwarm\", cbar=False, fmt=\".2f\", annot_kws={\"size\": 30})\n",
    "    ax.xaxis.set_tick_params(labelsize=40) # 设置x轴字体大小\n",
    "    ax.yaxis.set_tick_params(labelsize=40) # 设置y轴字体大小\n",
    "    plt.title('Factor Loadings Matrix', fontsize=40)\n",
    "    plt.ylabel('Variables', fontsize=40)# 设置y轴标签\n",
    "    plt.xlabel('Factors', fontsize=40)\n",
    "    plt.show()# 显示图片\n",
    "    \n",
    "    # 计算因子得分\n",
    "    factor_scores = Load_Matrix_rotated.transform(df_transposed)\n",
    "    df_scores = pd.DataFrame(factor_scores, index=df_transposed.index, columns=[f'Factor{i+1}' for i in range(18)])\n",
    "    \n",
    "    # 打印和保存因子得分\n",
    "    print(\"Factor Scores:\")\n",
    "    print(df_scores)\n",
    "    \n",
    "    scores_file_path = 'factor_scores.csv'\n",
    "    df_scores.to_csv(scores_file_path)\n",
    "    print(f\"Factor scores saved to {scores_file_path}\")\n",
    "    # 可视化因子得分的热图\n",
    "    plt.rcParams['font.family'] = 'Times New Roman'  # 设置英文字体为Times New Roman \n",
    "    plt.figure(figsize=(100, 200))\n",
    "    ax = sns.heatmap(df_scores, annot=True, center=0, cmap=\"coolwarm\", cbar=False, fmt=\".2f\", annot_kws={\"size\": 30})\n",
    "    plt.title('Factor Scores of molecular physicochemical properties', fontsize=40)\n",
    "    plt.xlabel('Factors', fontsize=40)\n",
    "    plt.ylabel('Physicochemical properties', fontsize=40)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=40) # 设置x轴字体大小\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=40) # 设置y轴字体大小\n",
    "    plt.show()  # 显示图片\n",
    "else:\n",
    "    print(\"The data is not suitable for factor analysis.\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:.conda-cyt]",
   "language": "python",
   "name": "conda-env-.conda-cyt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "760.148px",
    "left": "1813.65px",
    "right": "20px",
    "top": "115.992px",
    "width": "758.625px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
